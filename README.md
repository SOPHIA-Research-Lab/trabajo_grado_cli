# ğŸ”¬ Hologram Classifier v2.0 - Trabajo de Grado

**VersiÃ³n simplificada y mejorada del sistema de clasificaciÃ³n de hologramas para anemia falciforme**

## ğŸ¯ Objetivo

Sistema unificado que ejecuta **todo el anÃ¡lisis con un solo comando**, eliminando duplicaciÃ³n de cÃ³digo y mejorando la interpretabilidad de resultados.

## âš¡ EjecuciÃ³n RÃ¡pida (Un Solo Comando)

```bash
python run_analysis.py
```

Â¡Eso es todo! El sistema ejecutarÃ¡ automÃ¡ticamente:
1. âœ… **UnificaciÃ³n automÃ¡tica** del dataset (si es necesario)
2. âœ… Carga del dataset unificado
3. âœ… ExtracciÃ³n de caracterÃ­sticas (LBP, GLCM, FFT, Hu moments)  
4. âœ… Entrenamiento del modelo optimizado
5. âœ… ValidaciÃ³n cruzada + Leave-One-Out CV
6. âœ… AnÃ¡lisis de interpretabilidad
7. âœ… GeneraciÃ³n de visualizaciones
8. âœ… Reporte final completo

## ğŸ“ Estructura

```
hologram_classifier_v2/
â”œâ”€â”€ config.yaml           # ConfiguraciÃ³n central
â”œâ”€â”€ run_analysis.py       # ğŸ¯ COMANDO PRINCIPAL
â”œâ”€â”€ data/                 # ğŸ“ DATOS LOCALES (INCLUIDOS)
â”‚   â”œâ”€â”€ dataset_1/        # Dataset original (3000x4000)
â”‚   â”œâ”€â”€ dataset_2/        # Dataset adicional (1190x1585)
â”‚   â””â”€â”€ unified/          # Dataset unificado (se crea automÃ¡ticamente)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ hologram_analysis.py  # LÃ³gica unificada
â”‚   â””â”€â”€ dataset_unifier.py    # Unificador de datasets
â”œâ”€â”€ results/              # Resultados generados
â”‚   â”œâ”€â”€ analysis_report.txt
â”‚   â”œâ”€â”€ hologram_model.pkl
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â””â”€â”€ feature_distributions.png
â””â”€â”€ README.md            # Esta guÃ­a
```

## âš™ï¸ ConfiguraciÃ³n

Edita `config.yaml` para personalizar:

```yaml
# Rutas de datos
data_dir: "./data"                    # Carpeta con dataset_1 y dataset_2  
dataset_path: "./data/unified"        # Dataset unificado (se crea automÃ¡ticamente)
output_dir: "./results"               # Carpeta de resultados

# Modelo
model:
  target_size: [512, 512]             # TamaÃ±o de imÃ¡genes
  test_size: 0.2                      # Split train/test
  top_k_features: 20                  # CaracterÃ­sticas a seleccionar

# ValidaciÃ³n
validation:
  use_loocv: true                     # Usar Leave-One-Out CV
  n_cv_folds: 5                       # Folds para CV estÃ¡ndar

# VisualizaciÃ³n  
visualization:
  save_plots: true                    # Guardar grÃ¡ficos
  show_top_features: 10               # CaracterÃ­sticas a mostrar
```

## ğŸ“Š Resultados Esperados

DespuÃ©s de ejecutar `python run_analysis.py`:

### ğŸ“ˆ Performance TÃ­pico
- **Accuracy**: ~94-98%
- **AUC**: ~0.97-0.99
- **LOOCV Accuracy**: ~94%
- **Errores LOOCV**: 18-20/304 muestras

### ğŸ“„ Archivos Generados
- `analysis_report.txt`: Reporte completo con mÃ©tricas
- `hologram_model.pkl`: Modelo entrenado listo para usar
- `confusion_matrix.png`: Matriz de confusiÃ³n
- `feature_importance.png`: Top caracterÃ­sticas importantes
- `feature_distributions.png`: Distribuciones discriminativas

### ğŸ” Interpretabilidad
- âœ… Top caracterÃ­sticas mÃ¡s importantes identificadas
- âœ… Coeficientes del modelo interpretables  
- âœ… AnÃ¡lisis estadÃ­stico por clase (Cohen's d)
- âœ… Visualizaciones de distribuciones

## ğŸ› ï¸ Requisitos

```bash
pip install numpy pandas scikit-learn opencv-python matplotlib seaborn pyyaml scikit-image
```

## ğŸ“‹ Prerequisitos

1. **Datasets incluidos** en `./data/`
   ```
   data/
   â”œâ”€â”€ dataset_1/
   â”‚   â”œâ”€â”€ Healthy/    # CÃ©lulas sanas (3000x4000 px)
   â”‚   â””â”€â”€ SCD/        # CÃ©lulas SCD (3000x4000 px)
   â”œâ”€â”€ dataset_2/
   â”‚   â”œâ”€â”€ H-RBC/      # CÃ©lulas sanas (1190x1585 px)
   â”‚   â””â”€â”€ SCD-RBC/    # CÃ©lulas SCD (1190x1585 px)
   â””â”€â”€ unified/        # Se crea automÃ¡ticamente al ejecutar
       â”œâ”€â”€ Healthy/    # Combina ambos datasets
       â””â”€â”€ SCD/        # Combina ambos datasets
   ```

2. **Python 3.7+** con las librerÃ­as mencionadas

âœ… **VENTAJA**: El sistema unifica automÃ¡ticamente ambos datasets al ejecutarse, sin necesidad de preparaciÃ³n manual.

## ğŸš€ Ventajas vs VersiÃ³n Original

| Aspecto | Original | v2.0 Mejorada |
|---------|----------|---------------|
| **Comandos necesarios** | >10 scripts | **1 comando** |
| **CÃ³digo duplicado** | 2000+ lÃ­neas | **0 lÃ­neas** |
| **ConfiguraciÃ³n** | Hardcodeada | **Archivo YAML** |
| **PreparaciÃ³n de datos** | Manual compleja | **AutomÃ¡tica** |
| **Dependencias externas** | MÃºltiples rutas | **Auto-contenido** |
| **Interpretabilidad** | BÃ¡sica | **Mejorada con visualizaciones** |
| **Mantenimiento** | Complejo | **Simple y modular** |
| **Tiempo de ejecuciÃ³n** | ~10 min | **~3-5 min** |

## ğŸ› SoluciÃ³n de Problemas

### Error: "Dataset no encontrado"
```bash
# Verificar que existen los datasets base
ls ./data/
# Debe mostrar dataset_1/ y dataset_2/

# Si faltan, el sistema los crearÃ¡ automÃ¡ticamente
# O verificar dataset unificado creado:
ls ./data/unified/
# Debe mostrar carpetas Healthy/ y SCD/
```

### Error: "MÃ³dulo no encontrado" 
```bash
# Instalar dependencias
pip install -r requirements.txt
# O manualmente:
pip install numpy pandas scikit-learn opencv-python matplotlib seaborn pyyaml scikit-image
```

### Personalizar configuraciÃ³n
```bash
# Editar configuraciÃ³n
nano config.yaml
# Cambiar rutas, parÃ¡metros, etc.
```

## ğŸ“ Soporte

Para preguntas sobre el cÃ³digo o resultados:
1. Revisar `./results/analysis_report.txt` para detalles tÃ©cnicos
2. Verificar configuraciÃ³n en `config.yaml`
3. Comprobar que existen los datasets en `./data/dataset_1/` y `./data/dataset_2/`
4. El dataset unificado se crea automÃ¡ticamente en la primera ejecuciÃ³n

## ğŸ“ Uso para Trabajo de Grado

Este sistema simplificado estÃ¡ diseÃ±ado especÃ­ficamente para trabajos acadÃ©micos:

- **FÃ¡cil de ejecutar**: Un solo comando
- **Auto-contenido**: Todos los datos incluidos, sin dependencias externas
- **UnificaciÃ³n automÃ¡tica**: Combina datasets automÃ¡ticamente
- **Resultados reproducibles**: ConfiguraciÃ³n centralizada
- **Reportes automÃ¡ticos**: Listos para incluir en tesis
- **Visualizaciones claras**: Ideales para presentaciones
- **CÃ³digo limpio**: FÃ¡cil de revisar y modificar

**Â¡Perfecto para demostrar dominio tÃ©cnico sin complejidad innecesaria!** ğŸ¯